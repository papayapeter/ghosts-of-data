# ghosts-of-data
a ghost from data generator

## dependencies
* python 3.8.5
* [pytorch 16](https://pytorch.org/get-started/locally/)
* cuda 10.2
* [transformers](https://github.com/huggingface/transformers)

## research links
* [hugging face transformers generate script](https://github.com/huggingface/transformers/blob/master/examples/text-generation/run_generation.py)
* [transformers pretrained models](http://repo.continuum.io/miniconda/)
* [scientific paper on natural language generation explaining temperature, top-k smapling and other parameters we encountered in the 
transformers docu](https://arxiv.org/pdf/1904.09751.pdf)
* [Zamia german GPT-2](http://zamia-speech.org/brain/)
* [article train gpt 2 in your own language](https://towardsdatascience.com/train-gpt-2-in-your-own-language-fc6ad4d60171)
* [article Fine-tuning the English GPT-2 in any language](https://medium.com/@pierre_guillou/faster-than-training-from-scratch-fine-tuning-the-english-gpt-2-in-any-language-with-hugging-f2ec05c98787)

